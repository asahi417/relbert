model,accuracy
EleutherAI/gpt-j-6B,0.4266510267660664
EleutherAI/gpt-neo-1.3B,0.37990520653406096
EleutherAI/gpt-neo-125M,0.2917837299858348
EleutherAI/gpt-neo-2.7B,0.39259628523382845
EleutherAI/gpt-neox-20b,0.44057812772593163
bert-base-cased,0.31073285895082253
bert-large-cased,0.35441690691564953
facebook/opt-1.3b,0.3889905439720971
facebook/opt-125m,0.31161081561384707
facebook/opt-30b,0.4515117041105199
facebook/opt-350m,0.3481380199014311
facebook/opt-iml-1.3b,0.3856077908990892
facebook/opt-iml-30b,0.4548538504198583
facebook/opt-iml-max-1.3b,0.3929528603262724
facebook/opt-iml-max-30b,0.440911602261044
google/flan-t5-base,0.34495722180494093
google/flan-t5-large,0.35582876168364475
google/flan-t5-small,0.29875272233742844
google/flan-t5-xl,0.4522832293424176
google/flan-t5-xxl,0.48258340874395333
google/flan-ul2,0.4967580741488065
gpt2,0.2847778124650781
gpt2-large,0.36608228436403695
gpt2-medium,0.35653679484788847
gpt2-xl,0.37633041959746205
roberta-base,0.37273220860990125
roberta-large,0.44730729068414476
t5-11b,0.4005148892190586
t5-3b,0.2866480580680826
t5-base,0.26337066051854835
t5-large,0.29507188298706155
t5-small,0.29483045957744125
